{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ebecd6de1e7b4f1185e3f0eb83c80d77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b179e91e77d8439691e01d12e3f07ddd",
              "IPY_MODEL_73c8863d954e4709875aa82fb78b2987",
              "IPY_MODEL_d9184ef3ab9e439692275e0368b16b5b"
            ],
            "layout": "IPY_MODEL_f9acde9369d84b77b5e4e92faa431ee2"
          }
        },
        "b179e91e77d8439691e01d12e3f07ddd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf0bb27d7b32490c98d150040fa8fab2",
            "placeholder": "​",
            "style": "IPY_MODEL_a2df403b57e949cb92db7582ac2f3bc9",
            "value": "Map: 100%"
          }
        },
        "73c8863d954e4709875aa82fb78b2987": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c41f361b5cf4482a8574a91f44f498c0",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0cfd957cfd0b47869908d1016be23738",
            "value": 4
          }
        },
        "d9184ef3ab9e439692275e0368b16b5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af09ef03a67f4047a01baa66dbe0b40f",
            "placeholder": "​",
            "style": "IPY_MODEL_fc8cb26b95f0464c9e203809dd84c95e",
            "value": " 4/4 [00:00&lt;00:00, 44.59 examples/s]"
          }
        },
        "f9acde9369d84b77b5e4e92faa431ee2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf0bb27d7b32490c98d150040fa8fab2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2df403b57e949cb92db7582ac2f3bc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c41f361b5cf4482a8574a91f44f498c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cfd957cfd0b47869908d1016be23738": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "af09ef03a67f4047a01baa66dbe0b40f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc8cb26b95f0464c9e203809dd84c95e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Installation\n"
      ],
      "metadata": {
        "id": "SvOLj_3hl6TM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IT0X7WCylLKF",
        "outputId": "67edc551-9d93-43cc-e1fe-ad7b8167d2a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.14.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.29.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.14)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft) (1.5.2)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets peft torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import\n"
      ],
      "metadata": {
        "id": "-Peu4WGumCIs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# Load model directly\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\")\n",
        "device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model=model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R64jDomPlZDi",
        "outputId": "4c8720ff-4dc1-448d-a75d-b767e3e1ef8c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate Domain-Specific Document"
      ],
      "metadata": {
        "id": "N19Y9D56nLrF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"\"\"AI, short for Artificial Intelligence, is a field of technology focused on creating systems that can perform tasks typically requiring human intelligence. These tasks can include learning, problem-solving, language understanding, decision-making, and even recognizing patterns in data.\n",
        "In essence, AI is about teaching machines to \"think\" and adapt in ways that mimic human reasoning. It's used in a v\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "bmshmDFAnJDF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Converting Text data into huggig Face data"
      ],
      "metadata": {
        "id": "4-K79JJDoCPM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "sentences=text.split(\".\")\n",
        "dataset=Dataset.from_dict({\"text\":sentences})"
      ],
      "metadata": {
        "id": "2_iNs1hdoB7T"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABY_DlrunIR2",
        "outputId": "ca1c2b72-585e-4673-fcf1-c31ef0f2fffa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['AI, short for Artificial Intelligence, is a field of technology focused on creating systems that can perform tasks typically requiring human intelligence', ' These tasks can include learning, problem-solving, language understanding, decision-making, and even recognizing patterns in data', '\\nIn essence, AI is about teaching machines to \"think\" and adapt in ways that mimic human reasoning', \" It's used in a v\\n\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Examine the data schema"
      ],
      "metadata": {
        "id": "aAW7ISuJpqk9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Y0CwXVKpoB3",
        "outputId": "7b357c12-3f4b-4639-fe35-ad974651ae6f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'datasets.arrow_dataset.Dataset'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YU7MtiYDp5iL",
        "outputId": "2319a9a1-3643-40e9-de87-097707891d35"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text'],\n",
              "    num_rows: 4\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup Tokenizer"
      ],
      "metadata": {
        "id": "KUpGnhx8qQas"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function(examples):\n",
        "    inputs=tokenizer(examples[\"text\"],truncation=True,padding=\"max_length\",max_length=512)\n",
        "\n",
        "    inputs[\"labels\"]=inputs[\"input_ids\"].copy()\n",
        "    return inputs\n",
        "\n",
        "tokenized_dataset=dataset.map(preprocess_function,batched=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "ebecd6de1e7b4f1185e3f0eb83c80d77",
            "b179e91e77d8439691e01d12e3f07ddd",
            "73c8863d954e4709875aa82fb78b2987",
            "d9184ef3ab9e439692275e0368b16b5b",
            "f9acde9369d84b77b5e4e92faa431ee2",
            "bf0bb27d7b32490c98d150040fa8fab2",
            "a2df403b57e949cb92db7582ac2f3bc9",
            "c41f361b5cf4482a8574a91f44f498c0",
            "0cfd957cfd0b47869908d1016be23738",
            "af09ef03a67f4047a01baa66dbe0b40f",
            "fc8cb26b95f0464c9e203809dd84c95e"
          ]
        },
        "id": "Ybq9rma1qEBV",
        "outputId": "196165cc-ffa3-46e3-f6ae-dade6b50b9f0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/4 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ebecd6de1e7b4f1185e3f0eb83c80d77"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXq3Ayv3rpld",
        "outputId": "89375bc7-5337-4201-ab31-7fbb5d0813ca"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'input_ids', 'attention_mask', 'labels'],\n",
              "    num_rows: 4\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset[\"text\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRpdIngNrtgi",
        "outputId": "b64cb732-6c34-478c-f368-2f39740b980a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['AI, short for Artificial Intelligence, is a field of technology focused on creating systems that can perform tasks typically requiring human intelligence',\n",
              " ' These tasks can include learning, problem-solving, language understanding, decision-making, and even recognizing patterns in data',\n",
              " '\\nIn essence, AI is about teaching machines to \"think\" and adapt in ways that mimic human reasoning',\n",
              " \" It's used in a v\\n\"]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup LORA for efficient finetuning\n",
        "transforming huge model into small one with minimum parametres"
      ],
      "metadata": {
        "id": "gcHfUI3MsPmH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import get_peft_model, LoraConfig,TaskType\n",
        "lora_config= LoraConfig(\n",
        "    task_type=TaskType.CAUSAL_LM,\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    target_modules=[\"q_proj\",\"v_proj\"]\n",
        ")\n",
        "model = get_peft_model(model, lora_config)"
      ],
      "metadata": {
        "id": "nBDwfGsosXDf"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configuration of Training Hyperparameters"
      ],
      "metadata": {
        "id": "9U1xSpintY-E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments,Trainer\n",
        "training_args=TrainingArguments(\n",
        "    per_device_train_batch_size=1,\n",
        "    gradient_accumulation_steps=8,\n",
        "    warmup_steps=200,\n",
        "    num_train_epochs=150,\n",
        "    learning_rate=2e-4,\n",
        "    fp16=True,\n",
        "    logging_steps=10,\n",
        "    output_dir=\"outputs\",\n",
        "    report_to=\"none\",\n",
        "    remove_unused_columns=False\n",
        ")"
      ],
      "metadata": {
        "id": "mIPTfQQltWYV"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "memory optimisation tricks free up memory to avoid crush session"
      ],
      "metadata": {
        "id": "Powltyozue_-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=model.to(\"cpu\")\n",
        "trainer=Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        ")\n",
        "import torch\n",
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "model= torch.compile(model)\n",
        "model=model.to(\"cuda\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d37YqUM9ucrr",
        "outputId": "1c415a6f-7ed5-42e0-b622-00aafb18a3f6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "NG3NEapbvSfQ",
        "outputId": "8b654a65-b111-40e9-fada-19197805d6b7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [150/150 02:39, Epoch 150/150]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>9.986600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>9.182600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>6.636100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>2.993300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.474700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.163600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.148400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.128400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.113100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.099200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>0.085300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.070400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>0.055200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.041000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.031700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=150, training_loss=2.0139715458949405, metrics={'train_runtime': 163.2022, 'train_samples_per_second': 3.676, 'train_steps_per_second': 0.919, 'total_flos': 2849390670643200.0, 'train_loss': 2.0139715458949405, 'epoch': 150.0})"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save Models"
      ],
      "metadata": {
        "id": "KHsuvojLwcyb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "domain=\"madeby-Hana_ai-v1\"\n",
        "model.save_pretrained(f\"fine-tuned-deepseek_r1_1.5b-/{domain}\")\n",
        "tokenizer.save_pretrained(f\"fine-tuned-deepseek_r1_1.5b-/{domain}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlc48Nc_wDbg",
        "outputId": "4afb9254-8719-47be-edb2-eb339d5ba73a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('fine-tuned-deepseek_r1_1.5b-/madeby-Hana_ai-v1/tokenizer_config.json',\n",
              " 'fine-tuned-deepseek_r1_1.5b-/madeby-Hana_ai-v1/special_tokens_map.json',\n",
              " 'fine-tuned-deepseek_r1_1.5b-/madeby-Hana_ai-v1/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inference"
      ],
      "metadata": {
        "id": "WedUEkZvw8fE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM,AutoTokenizer\n",
        "import torch\n",
        "domain=\"madeby-Hana_ai-v1\"\n",
        "model_path=f\"fine-tuned-deepseek_r1_1.5b-/{domain}\"\n",
        "model=AutoModelForCausalLM.from_pretrained(model_path)\n",
        "tokenizer=AutoTokenizer.from_pretrained(model_path)\n",
        "device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model=model.to(device)\n"
      ],
      "metadata": {
        "id": "AMsmudPAw7bv"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AL-flr8qxqOU",
        "outputId": "a06c9ae8-b620-465f-aa2e-55d9c5f740c6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Qwen2ForCausalLM(\n",
              "  (model): Qwen2Model(\n",
              "    (embed_tokens): Embedding(151936, 1536)\n",
              "    (layers): ModuleList(\n",
              "      (0-27): 28 x Qwen2DecoderLayer(\n",
              "        (self_attn): Qwen2Attention(\n",
              "          (q_proj): lora.Linear(\n",
              "            (base_layer): Linear(in_features=1536, out_features=1536, bias=True)\n",
              "            (lora_dropout): ModuleDict(\n",
              "              (default): Dropout(p=0.05, inplace=False)\n",
              "            )\n",
              "            (lora_A): ModuleDict(\n",
              "              (default): Linear(in_features=1536, out_features=16, bias=False)\n",
              "            )\n",
              "            (lora_B): ModuleDict(\n",
              "              (default): Linear(in_features=16, out_features=1536, bias=False)\n",
              "            )\n",
              "            (lora_embedding_A): ParameterDict()\n",
              "            (lora_embedding_B): ParameterDict()\n",
              "            (lora_magnitude_vector): ModuleDict()\n",
              "          )\n",
              "          (k_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
              "          (v_proj): lora.Linear(\n",
              "            (base_layer): Linear(in_features=1536, out_features=256, bias=True)\n",
              "            (lora_dropout): ModuleDict(\n",
              "              (default): Dropout(p=0.05, inplace=False)\n",
              "            )\n",
              "            (lora_A): ModuleDict(\n",
              "              (default): Linear(in_features=1536, out_features=16, bias=False)\n",
              "            )\n",
              "            (lora_B): ModuleDict(\n",
              "              (default): Linear(in_features=16, out_features=256, bias=False)\n",
              "            )\n",
              "            (lora_embedding_A): ParameterDict()\n",
              "            (lora_embedding_B): ParameterDict()\n",
              "            (lora_magnitude_vector): ModuleDict()\n",
              "          )\n",
              "          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)\n",
              "        )\n",
              "        (mlp): Qwen2MLP(\n",
              "          (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
              "          (up_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
              "          (down_proj): Linear(in_features=8960, out_features=1536, bias=False)\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
              "        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
              "      )\n",
              "    )\n",
              "    (norm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
              "    (rotary_emb): Qwen2RotaryEmbedding()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=1536, out_features=151936, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(prompt, max_length=200):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device) # Changed line\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(\n",
        "            input_ids=inputs.input_ids, # Changed line\n",
        "            attention_mask=inputs.attention_mask, # Changed line\n",
        "            max_length=max_length,\n",
        "            temperature=0.7,\n",
        "            top_k=50,\n",
        "            top_p=0.9,\n",
        "        )\n",
        "    return tokenizer.decode(output[0], skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "JVCUwriExyQO"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=\"Artificial Intelligence, or AI, refers to systems or machines designed to mimic human intelligence to perform tasks and improve themselves\"\n",
        "generated_text=generate_text(prompt,max_length=1024)\n",
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXCgl5Rsyz6-",
        "outputId": "2376bc67-c276-42ae-86ac-680bff039e08"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Artificial Intelligence, or AI, refers to systems or machines designed to mimic human intelligence to perform tasks and improve themselves. \n",
            "\n",
            "In this context, when discussing AI, what are the key factors that influence its development and progress?\n",
            "\n",
            "I know that one factor is the availability of data. AI systems need data to learn and improve. But what if the data isn't reliable or isn't diverse enough? How does that affect AI's ability to generalize and perform tasks effectively?\n",
            "\n",
            "Another factor I've heard about is the complexity of AI algorithms. AI systems are built using various algorithms, each with different strengths and weaknesses. How does the complexity of these algorithms influence their performance and scalability?\n",
            "\n",
            "Lastly, I'm considering the ethical implications of AI. As AI becomes more integrated into society, issues like bias, privacy, and job displacement come into play. How can we ensure that AI is developed and used in a way that respects human values and avoids unintended consequences?\n",
            "\n",
            "Additionally, I wonder if there are other factors beyond these three. What role do educational institutions play in shaping AI development and progress? And how does public perception influence the progress of AI?\n",
            "\n",
            "I'm also thinking about the practical applications of AI. It's used in healthcare, finance, education, and entertainment. How do these applications influence the development of AI, and what challenges do they present?\n",
            "\n",
            "Moreover, I'm curious about how different regions and cultures have varying impacts on AI development. For example, in some countries, AI adoption is faster than in others. What factors might be driving these differences?\n",
            "\n",
            "I should also consider the role of government policies. How do policies like tax incentives or regulations affect AI development and deployment?\n",
            "\n",
            "Lastly, I'm thinking about the future of AI. What trends are likely to shape AI's development, and how will these trends be supported by technological advancements?\n",
            "\n",
            "In summary, I need to identify the key factors that influence AI development and progress, beyond the ones I initially listed. I should also consider the broader implications, including ethical, educational, cultural, and economic factors, as well as how different regions and cultures influence AI development and its applications.\n",
            "</think>\n",
            "\n",
            "The development and progress of Artificial Intelligence (AI) can be influenced by a variety of factors beyond the initial considerations. Here is an organized summary of the key factors:\n",
            "\n",
            "### Factors Influencing AI Development and Progress\n",
            "\n",
            "1. **Data Availability and Quality**\n",
            "   - **Reliability and Diversity**: The quality and diversity of data significantly impact AI's ability to generalize and perform tasks effectively. Inadequate or biased data can limit AI's adaptability.\n",
            "   \n",
            "2. **Algorithm Complexity and Performance**\n",
            "   - **Algorithm Strengths and Weaknesses**: The complexity of AI algorithms can affect their scalability and performance. Stronger algorithms may not be suitable for all tasks, necessitating careful selection and adaptation.\n",
            "\n",
            "3. **Ethical and Legal Implications**\n",
            "   - **Bias, Privacy, and Job Displacement**: Issues such as bias in AI development and the protection of personal data are critical. Ensuring ethical practices and addressing privacy concerns are essential for responsible AI deployment.\n",
            "\n",
            "4. **Education and Awareness**\n",
            "   - **Educational Institutions**: These play a crucial role in shaping AI development by providing curricula, training programs, and funding. They influence the next generation's understanding and engagement with AI.\n",
            "\n",
            "5. **Public Perception and Culture**\n",
            "   - **Cultural and Political Influences**: Cultural attitudes toward AI can drive adoption rates. Political factors, such as regulations and funding, also influence the trajectory of AI development.\n",
            "\n",
            "6. **Government Policies**\n",
            "   - **Tax Incentives and Regulations**: Policies like tax incentives and regulations can accelerate AI adoption, particularly in regions where cost is a factor.\n",
            "\n",
            "7. **Region and Culture**\n",
            "   - **Geographical and Cultural Factors**: Different regions may have varying adoption rates due to factors like infrastructure, availability of skilled workforce, and cultural attitudes towards technology.\n",
            "\n",
            "8. **Practical Applications**\n",
            "   - **Healthcare, Finance, Education, Entertainment**: AI's applications in various sectors present unique challenges, such as data security in healthcare and algorithmic bias in finance.\n",
            "\n",
            "9. **Future Trends and Support**\n",
            "   - **Trends like AI as a Service and Autonomous Systems**: Technological advancements and trends are driving the future of AI, with support from research, development, and policy-making.\n",
            "\n",
            "### Conclusion\n",
            "\n",
            "The factors influencing AI development and progress are multifaceted, encompassing data, algorithms, ethics, education, policies, cultural impacts, and societal applications. Addressing these factors will drive the future of AI, ensuring its responsible and effective development and deployment.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "output is inot a simple reasoning but generation with reasoning capabilities\n",
        "to increase creativity we can increase temperature.\n",
        "we notice that Deepseek is asking himself.\n",
        ""
      ],
      "metadata": {
        "id": "7FW2zPzlz9P7"
      }
    }
  ]
}