# Fine-Tuning DeepSeek-R1-Distill-Qwen-1.5B with LoRA

# Overview

This project demonstrates fine-tuning the DeepSeek-R1-Distill-Qwen-1.5B model using LoRA (Low-Rank Adaptation) for efficient domain-specific adaptation. The process involves setting up the model, tokenizing the dataset, applying LoRA for fine-tuning, training, and finally saving and using the fine-tuned model for inference.
